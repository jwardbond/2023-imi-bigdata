{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfea226-5f01-48bd-a0bd-8abd9d5206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import coo_array\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293d781",
   "metadata": {},
   "source": [
    "# 2. Custom Method\n",
    "\n",
    "This method adapts the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). In that work, the random walk uses relative edge weights to assign probabilities of traversing edges from a given node. This means edges are weighted *locally* - around a given node - but not *globally*. \n",
    "\n",
    "In this method, I use the weighted pagerank method from Zhang *et al.,*, but I adjust the gamma parameter - the probability of randomly teleporting from any node - to be *node specific* and based on the total edge suspicion of a given node.\n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    \\theta w_{ji}/s_j^{out} + (1-\\theta)a_{ji}/d_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\boldsymbol{\\gamma} MP + (1-\\boldsymbol{\\gamma})\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\boldsymbol{\\gamma}$ is a vector of hyperparameters representing the probability of randomly teleporting from a given node\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "157b8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 1\n",
    "REVERSE = True\n",
    "\n",
    "DATAPATH = Path('../data/processed/pagerank')\n",
    "OUTPATH = DATAPATH.parent / 'nodes_custom_rev.parquet'\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'input_node_scores.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'input_edge_scores.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98042e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE:\n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344371c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b179828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>b_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99473</th>\n",
       "      <td>CUST76986222</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118407</th>\n",
       "      <td>CUST60968343</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21260</th>\n",
       "      <td>CUST73079564</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust_id       b_i\n",
       "99473   CUST76986222  0.000672\n",
       "118407  CUST60968343  0.000662\n",
       "21260   CUST73079564  0.000624"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab29c6",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3db642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146211</th>\n",
       "      <td>229329</td>\n",
       "      <td>188039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127279</th>\n",
       "      <td>10679</td>\n",
       "      <td>249564</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214667</th>\n",
       "      <td>153618</td>\n",
       "      <td>110197</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id_sender  cust_id_receiver  score\n",
       "146211          229329            188039    0.0\n",
       "127279           10679            249564    0.0\n",
       "214667          153618            110197    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0b9d0",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d50828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92823</th>\n",
       "      <td>22538</td>\n",
       "      <td>3700</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885602</th>\n",
       "      <td>224135</td>\n",
       "      <td>46552</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908509</th>\n",
       "      <td>230753</td>\n",
       "      <td>64343</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681854</th>\n",
       "      <td>168951</td>\n",
       "      <td>219601</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333676</th>\n",
       "      <td>82209</td>\n",
       "      <td>133365</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781247</th>\n",
       "      <td>193874</td>\n",
       "      <td>189126</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809426</th>\n",
       "      <td>201875</td>\n",
       "      <td>12177</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602934</th>\n",
       "      <td>149025</td>\n",
       "      <td>122156</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040335</th>\n",
       "      <td>269048</td>\n",
       "      <td>53554</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.185000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462708</th>\n",
       "      <td>114004</td>\n",
       "      <td>292736</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cust_id_sender  cust_id_receiver     score      w_ji  a_ji       s_j  \\\n",
       "92823             22538              3700  0.010000  0.010000     1  0.195000   \n",
       "885602           224135             46552  0.010000  0.010000     1  0.400000   \n",
       "908509           230753             64343  0.343333  0.343333     1  0.686667   \n",
       "681854           168951            219601  0.010000  0.010000     1  0.305000   \n",
       "333676            82209            133365  0.010000  0.010000     1  0.020000   \n",
       "781247           193874            189126  0.010000  0.010000     1  0.165000   \n",
       "809426           201875             12177  0.010000  0.010000     1  0.050000   \n",
       "602934           149025            122156  0.010000  0.010000     1  0.508333   \n",
       "1040335          269048             53554  0.135000  0.135000     1  0.185000   \n",
       "462708           114004            292736  0.010000  0.010000     1  0.195000   \n",
       "\n",
       "         d_j  \n",
       "92823      7  \n",
       "885602    15  \n",
       "908509     2  \n",
       "681854    18  \n",
       "333676     2  \n",
       "781247     4  \n",
       "809426     5  \n",
       "602934     5  \n",
       "1040335    6  \n",
       "462708     7  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify matrix is column stochastic... m should all be 1.0\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa042417",
   "metadata": {},
   "source": [
    "## Calculate $\\boldsymbol{\\gamma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gammas\n",
    "gamma_df = e_df.groupby(['cust_id_sender'], as_index=False)['s_j'].max() #trick, all s_j are the same\n",
    "gamma_df['gamma'] = np.exp(gamma_df['s_j'])/(0.8+np.exp(gamma_df['s_j']))\n",
    "gamma_df = gamma_df.rename(columns={'cust_id_sender': 'cust_id'})\n",
    "\n",
    "# Create gamma array\n",
    "gamma_df = gamma_df.merge(b_df, on='cust_id', how='right') #trick to get all node ids\n",
    "gamma_df = gamma_df.fillna(np.exp(0)/(0.8+np.exp(0)))\n",
    "gamma_df = gamma_df.sort_values(['cust_id'])\n",
    "gamma = gamma_df['gamma'].values\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15517c03",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pagerank(M, B, P, gamma, tol=1e-10, maxit=1000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank using a custom algorithm\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: An array of probabilities of randomly teleporting from a given node (Nx1)\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = gamma*M.dot(P) + (1-gamma)*B\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = custom_pagerank(M, B, P, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf5ff1",
   "metadata": {},
   "source": [
    "## Exporting for Webapp\n",
    "The pagerank data needs to be converted back into KYC-esque data, with customer names, countries, etc. but this needs to include *external customers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pagerank_results(pagerank_df):\n",
    "    \"\"\"Takes in a [id, score] dataframe and turns it back into KYC-style data\"\"\"\n",
    "    \n",
    "    datapath = Path('../data/processed/')\n",
    "    \n",
    "    kyc_df = pd.read_parquet(datapath / 'kyc.parquet')\n",
    "    wdf = pd.read_parquet(datapath / 'wire.parquet')\n",
    "    edf = pd.read_parquet(datapath / 'emt.parquet')\n",
    "    \n",
    "    cleaned = pagerank_df.copy()\n",
    "    \n",
    "    # Join with kyc data and add country column\n",
    "    kyc_df['country'] = 'CA'\n",
    "    cleaned = pd.merge(cleaned, kyc_df, how='left', on='cust_id')\n",
    "\n",
    "    # Get additional countries from wiretransfer data\n",
    "    s1 = wdf[['cust_id_sender', 'country_sender']].copy().rename(columns={'cust_id_sender':'cust_id', 'country_sender':'country'})\n",
    "    s2 = wdf[['cust_id_receiver', 'country_receiver']].copy().rename(columns={'cust_id_receiver':'cust_id', 'country_receiver':'country'})\n",
    "    countries = pd.concat([s1,s2])\n",
    "    countries = countries.drop_duplicates()\n",
    "\n",
    "    cleaned = pd.merge(cleaned, countries, how='left', on='cust_id')\n",
    "    cleaned['country_x'] = cleaned['country_x'].combine_first(cleaned['country_y'])\n",
    "    cleaned['country'] = cleaned['country_x']\n",
    "    cleaned = cleaned.drop(columns=['country_x', 'country_y'])\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df = clean_pagerank_results(P_df)\n",
    "P_df.to_parquet(OUTPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f4a04",
   "metadata": {},
   "source": [
    "## Vis\n",
    "jw = 'CUST33059790'\n",
    "mw = 'CUST48666641'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df.groupby('cust_id_sender').max().sort_values('s_j')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caa054",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf = pd.read_parquet('../data/processed/kyc.parquet')\n",
    "idx = le.inverse_transform([138529])[0]\n",
    "jwid = le.transform(['CUST33059790'])[0]\n",
    "\n",
    "kdf[kdf.cust_id==idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = e_df.copy()\n",
    "edf[(edf.cust_id_sender==138529)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff9263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = e_df.copy()\n",
    "edf[(edf.cust_id_sender==50119)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf[kdf.cust_id==le.inverse_transform([164781])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12215cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf[kdf['named_trafficker']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761c5d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imibigdata]",
   "language": "python",
   "name": "conda-env-imibigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
