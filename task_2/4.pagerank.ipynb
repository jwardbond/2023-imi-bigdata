{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfea226-5f01-48bd-a0bd-8abd9d5206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import coo_array\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633721e6-cf0d-4cd7-9df0-28a3d0316785",
   "metadata": {},
   "source": [
    "# 1. Zhang et al. Method\n",
    "This method uses the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). \n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    \\theta w_{ji}/s_j^{out} + (1-\\theta)a_{ji}/d_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\gamma MP + (1-\\gamma)\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\gamma$ is a tunable parameter representing the probability of restarting a random walk (typically 0.8-0.9)\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1b46f95-cf7e-4c31-b530-35bb784e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 0.8\n",
    "GAMMA = 0.9\n",
    "REVERSE = True\n",
    "\n",
    "DATAPATH = Path('../data/processed/pagerank')\n",
    "OUTPATH = DATAPATH.parent / 'nodes_new.parquet'\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'input_node_scores.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'input_edge_scores.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee75c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE: \n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452c23d-0ff9-4ea8-84b6-e0a6a4e752d7",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6e38a9d-d87d-47df-a950-ea2e0614c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9da848d-28fa-4ba7-a223-01ab53da7074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>b_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293824</th>\n",
       "      <td>CUST43500432</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43149</th>\n",
       "      <td>CUST97363176</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198070</th>\n",
       "      <td>CUST27210892</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust_id       b_i\n",
       "293824  CUST43500432  0.000117\n",
       "43149   CUST97363176  0.000107\n",
       "198070  CUST27210892  0.000107"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec027c-8c55-4a4a-81ee-2d2275cd2b4a",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c43742b6-a5f3-48ea-a997-cb989d64106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467963</th>\n",
       "      <td>257216</td>\n",
       "      <td>71199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481027</th>\n",
       "      <td>55047</td>\n",
       "      <td>198966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483673</th>\n",
       "      <td>226239</td>\n",
       "      <td>97259</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id_sender  cust_id_receiver  score\n",
       "467963          257216             71199    0.0\n",
       "481027           55047            198966    0.0\n",
       "483673          226239             97259    0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b898d-f086-43e6-940d-7431d9abf66c",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c33008b5-31d1-42be-b60f-504b34e97c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506747</th>\n",
       "      <td>125065</td>\n",
       "      <td>173374</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411202</th>\n",
       "      <td>101494</td>\n",
       "      <td>123670</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720509</th>\n",
       "      <td>178563</td>\n",
       "      <td>243998</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331677</th>\n",
       "      <td>81729</td>\n",
       "      <td>8492</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472870</th>\n",
       "      <td>116591</td>\n",
       "      <td>53090</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482227</th>\n",
       "      <td>118935</td>\n",
       "      <td>232960</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>0.343333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049690</th>\n",
       "      <td>271802</td>\n",
       "      <td>83687</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112241</th>\n",
       "      <td>290094</td>\n",
       "      <td>91171</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736928</th>\n",
       "      <td>182648</td>\n",
       "      <td>263226</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.960000</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726720</th>\n",
       "      <td>180123</td>\n",
       "      <td>31664</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cust_id_sender  cust_id_receiver     score      w_ji  a_ji       s_j  \\\n",
       "506747           125065            173374  0.010000  0.010000     1  0.010000   \n",
       "411202           101494            123670  0.260000  0.260000     1  1.240000   \n",
       "720509           178563            243998  0.010000  0.010000     1  0.050000   \n",
       "331677            81729              8492  0.260000  0.260000     1  0.520000   \n",
       "472870           116591             53090  0.010000  0.010000     1  0.400000   \n",
       "482227           118935            232960  0.343333  0.343333     1  0.473333   \n",
       "1049690          271802             83687  0.010000  0.010000     1  0.340000   \n",
       "1112241          290094             91171  0.010000  0.010000     1  0.030000   \n",
       "736928           182648            263226  0.260000  0.260000     1  5.960000   \n",
       "726720           180123             31664  0.010000  0.010000     1  0.070000   \n",
       "\n",
       "         d_j  \n",
       "506747     1  \n",
       "411202    24  \n",
       "720509     5  \n",
       "331677     2  \n",
       "472870    15  \n",
       "482227    14  \n",
       "1049690    9  \n",
       "1112241    3  \n",
       "736928    21  \n",
       "726720     7  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a03c3ebd-dac6-4a8d-b3d4-f48df33f1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87832768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26951</th>\n",
       "      <td>1262053</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>7</td>\n",
       "      <td>14.49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250414</th>\n",
       "      <td>1595174</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14</td>\n",
       "      <td>5.46</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63154</th>\n",
       "      <td>1289035</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>7</td>\n",
       "      <td>14.49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id_receiver  score  w_ji  a_ji    s_j  d_j    m\n",
       "cust_id_sender                                                      \n",
       "26951                    1262053   2.07  2.07     7  14.49   49  1.0\n",
       "250414                   1595174   0.39  0.39    14   5.46  196  1.0\n",
       "63154                    1289035   2.07  2.07     7  14.49   49  1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify matrix is column stochastic... output m should be 1\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da69d5b-0a20-46fa-a495-b1f26a55a21e",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f892e140-700e-4eba-b736-d417d34a5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pagerank(M, B, P, gamma=0.85, tol=1e-10, maxit=1000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: A hyperparam representing the probability of a random surfer NOT making a random jump to a new node\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = GAMMA*M.dot(P) + (1-GAMMA)*B\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20daf23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max (relative) error: 8.8e-11\n",
      "Final iterations: 247\n"
     ]
    }
   ],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = weighted_pagerank(M, B, P, GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741a0f0d",
   "metadata": {},
   "source": [
    "## Exporting for Webapp\n",
    "The pagerank data needs to be converted back into KYC-esque data, with customer names, countries, etc. but this needs to include *external customers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06919b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pagerank_results(pagerank_df):\n",
    "    \"\"\"Takes in a [id, score] dataframe and turns it back into KYC-style data\"\"\"\n",
    "    \n",
    "    datapath = Path('../data/processed/')\n",
    "    \n",
    "    kyc_df = pd.read_parquet(datapath / 'kyc.parquet')\n",
    "    wdf = pd.read_parquet(datapath / 'wire.parquet')\n",
    "    edf = pd.read_parquet(datapath / 'emt.parquet')\n",
    "    \n",
    "    cleaned = pagerank_df.copy()\n",
    "    \n",
    "    # Join with kyc data and add country column\n",
    "    kyc_df['country'] = 'CA'\n",
    "    cleaned = pd.merge(cleaned, kyc_df, how='left', on='cust_id')\n",
    "\n",
    "    # Get additional countries from wiretransfer data\n",
    "    s1 = wdf[['cust_id_sender', 'country_sender']].copy().rename(columns={'cust_id_sender':'cust_id', 'country_sender':'country'})\n",
    "    s2 = wdf[['cust_id_receiver', 'country_receiver']].copy().rename(columns={'cust_id_receiver':'cust_id', 'country_receiver':'country'})\n",
    "    countries = pd.concat([s1,s2])\n",
    "    countries = countries.drop_duplicates()\n",
    "\n",
    "    cleaned = pd.merge(cleaned, countries, how='left', on='cust_id')\n",
    "    cleaned['country_x'] = cleaned['country_x'].combine_first(cleaned['country_y'])\n",
    "    cleaned['country'] = cleaned['country_x']\n",
    "    cleaned = cleaned.drop(columns=['country_x', 'country_y'])\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e88c7b2c-35ba-43b2-9fcd-d66b78e60195",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df = clean_pagerank_results(P_df)\n",
    "P_df.to_parquet(OUTPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfcdc82",
   "metadata": {},
   "source": [
    "# UNDER CONSTRUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293d781",
   "metadata": {},
   "source": [
    "# 2. Custom Method\n",
    "\n",
    "This method adapts the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). In that work, the random walk uses relative edge weights to assign probabilities of traversing edges from a given node. This means edges are weighted *locally* - around a given node - but not *globally*. \n",
    "\n",
    "In this method, I use the weighted pagerank method from Zhang *et al.,*, but I adjust the gamma parameter - the probability of randomly teleporting from any node - to be *node specific* and based on the total edge suspicion of a given node.\n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    w_{ji}/s_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\boldsymbol{\\gamma} MP + (1-\\boldsymbol{\\gamma})\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\boldsymbol{\\gamma}$ is a vector of hyperparameters representing the probability of randomly teleporting from a given node\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "157b8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path('../data/processed')\n",
    "REVERSE = True\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'pr_node_score.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'pr_edge_score.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98042e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE:\n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344371c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab29c6",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3db642",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0b9d0",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d50828",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify matrix is column stochastic... m should all be 1.0\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403e67c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\gamma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15517c03",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pagerank(M, B, P, gamma, tol=1e-10, maxit=1000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank using a custom algorithm\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: An array of probabilities of randomly teleporting from a given node (Nx1)\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = GAMMA*M.dot(P) + (1-GAMMA)*B\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = weighted_pagerank(M, B, P, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884db066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df.to_parquet(DATAPATH / 'pagerank_rev_edge.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2c6de-4df0-4542-990b-dbe9c4fa8d15",
   "metadata": {},
   "source": [
    "# Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ce0838f-edd8-465f-813d-1e10e39ce345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaleido version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import kaleido \n",
    "print('kaleido version:', kaleido.__version__)\n",
    "\n",
    "#Inline figures\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "#Themeing\n",
    "# mcolors = px.colors.qualitative.Dark24\n",
    "\n",
    "pio.templates['custom'] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        xaxis=dict(ticks='outside', tickcolor='lightgray', showgrid=False, showline=True),\n",
    "        yaxis=dict(ticks='outside', tickcolor='lightgray', showgrid=False, showline=True, mirror=True),\n",
    "        yaxis2=dict(ticks='outside', tickcolor='lightgray', showgrid=False,),\n",
    "        # colorway=mcolors,\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "pio.templates.default = 'plotly_white+custom'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imibigdata]",
   "language": "python",
   "name": "conda-env-imibigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
