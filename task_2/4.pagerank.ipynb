{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dfea226-5f01-48bd-a0bd-8abd9d5206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import coo_array\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "# from cdlib import algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633721e6-cf0d-4cd7-9df0-28a3d0316785",
   "metadata": {},
   "source": [
    "# 1. Zhang et al. Method\n",
    "This method uses the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). \n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    \\theta w_{ji}/s_j^{out} + (1-\\theta)a_{ji}/d_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\gamma MP + (1-\\gamma)\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\gamma$ is a tunable parameter representing the probability of restarting a random walk (typically 0.8-0.9)\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b46f95-cf7e-4c31-b530-35bb784e7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 0.8\n",
    "GAMMA = 0.9\n",
    "REVERSE = True\n",
    "\n",
    "DATAPATH = Path('../data/processed/pagerank')\n",
    "OUTPATH = DATAPATH / 'output.parquet'\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'input_node_scores.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'input_edge_scores.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee75c127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE: \n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452c23d-0ff9-4ea8-84b6-e0a6a4e752d7",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6e38a9d-d87d-47df-a950-ea2e0614c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9da848d-28fa-4ba7-a223-01ab53da7074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>b_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50110</th>\n",
       "      <td>CUST23925850</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174387</th>\n",
       "      <td>CUST84626197</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141206</th>\n",
       "      <td>CUST29413585</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust_id       b_i\n",
       "50110   CUST23925850  0.000083\n",
       "174387  CUST84626197  0.000083\n",
       "141206  CUST29413585  0.000083"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec027c-8c55-4a4a-81ee-2d2275cd2b4a",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c43742b6-a5f3-48ea-a997-cb989d64106e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494546</th>\n",
       "      <td>50555</td>\n",
       "      <td>240147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170120</th>\n",
       "      <td>50386</td>\n",
       "      <td>228220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49088</th>\n",
       "      <td>214440</td>\n",
       "      <td>101727</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id_sender  cust_id_receiver  score\n",
       "494546           50555            240147    0.0\n",
       "170120           50386            228220    0.0\n",
       "49088           214440            101727    0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2b898d-f086-43e6-940d-7431d9abf66c",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c33008b5-31d1-42be-b60f-504b34e97c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694262</th>\n",
       "      <td>172069</td>\n",
       "      <td>97432</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73742</th>\n",
       "      <td>18061</td>\n",
       "      <td>214915</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539706</th>\n",
       "      <td>133144</td>\n",
       "      <td>72333</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988835</th>\n",
       "      <td>254013</td>\n",
       "      <td>192956</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480538</th>\n",
       "      <td>118520</td>\n",
       "      <td>197099</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>1</td>\n",
       "      <td>7.973333</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353513</th>\n",
       "      <td>87217</td>\n",
       "      <td>266010</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139875</th>\n",
       "      <td>34104</td>\n",
       "      <td>260381</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300629</th>\n",
       "      <td>73921</td>\n",
       "      <td>285072</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86789</th>\n",
       "      <td>21239</td>\n",
       "      <td>43342</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961644</th>\n",
       "      <td>246087</td>\n",
       "      <td>25918</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id_sender  cust_id_receiver     score      w_ji  a_ji       s_j  \\\n",
       "694262          172069             97432  0.010000  0.010000     1  0.020000   \n",
       "73742            18061            214915  0.010000  0.010000     1  0.010000   \n",
       "539706          133144             72333  0.510000  0.510000     1  8.650000   \n",
       "988835          254013            192956  0.010000  0.010000     1  0.870000   \n",
       "480538          118520            197099  0.843333  0.843333     1  7.973333   \n",
       "353513           87217            266010  0.010000  0.010000     1  0.050000   \n",
       "139875           34104            260381  0.010000  0.010000     1  0.010000   \n",
       "300629           73921            285072  0.510000  0.510000     1  2.550000   \n",
       "86789            21239             43342  0.010000  0.010000     1  1.160000   \n",
       "961644          246087             25918  0.510000  0.510000     1  2.860000   \n",
       "\n",
       "        d_j  \n",
       "694262    2  \n",
       "73742     1  \n",
       "539706   15  \n",
       "988835   12  \n",
       "480538   14  \n",
       "353513    5  \n",
       "139875    1  \n",
       "300629    5  \n",
       "86789    16  \n",
       "961644   11  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a03c3ebd-dac6-4a8d-b3d4-f48df33f1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87832768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38929</th>\n",
       "      <td>3977510</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>23</td>\n",
       "      <td>16.79</td>\n",
       "      <td>529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64911</th>\n",
       "      <td>4000942</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>23</td>\n",
       "      <td>16.79</td>\n",
       "      <td>529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142376</th>\n",
       "      <td>876084</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.07</td>\n",
       "      <td>7</td>\n",
       "      <td>14.49</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id_receiver  score  w_ji  a_ji    s_j  d_j    m\n",
       "cust_id_sender                                                      \n",
       "38929                    3977510   0.73  0.73    23  16.79  529  1.0\n",
       "64911                    4000942   0.73  0.73    23  16.79  529  1.0\n",
       "142376                    876084   2.07  2.07     7  14.49   49  1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify matrix is column stochastic... output m should be 1\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da69d5b-0a20-46fa-a495-b1f26a55a21e",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f892e140-700e-4eba-b736-d417d34a5d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_pagerank(M, B, P, gamma=0.85, tol=1e-10, maxit=1000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: A hyperparam representing the probability of a random surfer NOT making a random jump to a new node\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = GAMMA*M.dot(P) + (1-GAMMA)*B\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20daf23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max (relative) error: 8.98e-11\n",
      "Final iterations: 245\n"
     ]
    }
   ],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = weighted_pagerank(M, B, P, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e88c7b2c-35ba-43b2-9fcd-d66b78e60195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df.to_parquet(OUTPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293d781",
   "metadata": {},
   "source": [
    "# 2. Custom Method\n",
    "\n",
    "This method adapts the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). In that work, the random walk uses relative edge weights to assign probabilities of traversing edges from a given node. This means edges are weighted *locally* - around a given node - but not *globally*. \n",
    "\n",
    "In this method, I use the weighted pagerank method from Zhang *et al.,*, but I adjust the gamma parameter - the probability of randomly teleporting from any node - to be *node specific* and based on the total edge suspicion of a given node.\n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    w_{ji}/s_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\boldsymbol{\\gamma} MP + (1-\\boldsymbol{\\gamma})\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\boldsymbol{\\gamma}$ is a vector of hyperparameters representing the probability of randomly teleporting from a given node\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "157b8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path('../data/processed')\n",
    "REVERSE = True\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'pr_node_score.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'pr_edge_score.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98042e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE:\n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344371c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab29c6",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3db642",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0b9d0",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d50828",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify matrix is column stochastic... m should all be 1.0\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6403e67c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\gamma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15517c03",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pagerank(M, B, P, gamma, tol=1e-10, maxit=1000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank using a custom algorithm\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: An array of probabilities of randomly teleporting from a given node (Nx1)\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = GAMMA*M.dot(P) + (1-GAMMA)*B\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = weighted_pagerank(M, B, P, GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884db066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df.to_parquet(DATAPATH / 'pagerank_rev_edge.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2c6de-4df0-4542-990b-dbe9c4fa8d15",
   "metadata": {},
   "source": [
    "# Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ce0838f-edd8-465f-813d-1e10e39ce345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaleido version: 0.2.1\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import kaleido \n",
    "print('kaleido version:', kaleido.__version__)\n",
    "\n",
    "#Inline figures\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "#Themeing\n",
    "# mcolors = px.colors.qualitative.Dark24\n",
    "\n",
    "pio.templates['custom'] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        xaxis=dict(ticks='outside', tickcolor='lightgray', showgrid=False, showline=True),\n",
    "        yaxis=dict(ticks='outside', tickcolor='lightgray', showgrid=False, showline=True, mirror=True),\n",
    "        yaxis2=dict(ticks='outside', tickcolor='lightgray', showgrid=False,),\n",
    "        # colorway=mcolors,\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "pio.templates.default = 'plotly_white+custom'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imibigdata]",
   "language": "python",
   "name": "conda-env-imibigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
