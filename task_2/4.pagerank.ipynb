{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dfea226-5f01-48bd-a0bd-8abd9d5206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import coo_array\n",
    "from pathlib import Path\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293d781",
   "metadata": {},
   "source": [
    "# 2. Custom Method\n",
    "\n",
    "This method adapts the pagerank technique outlined in [Zhang *et al.,* 2022](https://arxiv.org/abs/2104.02764). In that work, the random walk uses relative edge weights to assign probabilities of traversing edges from a given node. This means edges are weighted *locally* - around a given node - but not *globally*. \n",
    "\n",
    "In this method, I use the weighted pagerank method from Zhang *et al.,*, but I adjust the gamma parameter - the probability of randomly teleporting from any node - to be *node specific* and based on the total edge suspicion of a given node.\n",
    "\n",
    "Mainly: \n",
    "\n",
    "Let $M$ be a transition matrix with: \n",
    "$$m_{ij} = \\begin{cases}\n",
    "    \\theta w_{ji}/s_j^{out} + (1-\\theta)a_{ji}/d_j^{out} && \\texttt{if}\\; d_j^{out}\\neq 0\\\\\n",
    "    0 && \\texttt{if}\\; d_j^{out}=0\n",
    "\\end{cases}$$\n",
    "Where: \n",
    "- $\\theta$ is a tunable parameter that represents how important edge weights should be in the pagerank alg\n",
    "- $w_{ji}$ is the weight of an edge from node $j \\rightarrow i$\n",
    "- $s_j^{out} = \\sum_{v \\in V|j \\rightarrow v}w_{jv}$ is the \"strength\" of outgoing edges from node $j$\n",
    "- $a_{ji}$ = $1 \\:\\texttt{if}\\: j \\rightarrow i \\:\\texttt{else}\\: 0$\n",
    "- $d_j^{out} = \\sum_{v \\in V|j \\rightarrow v}a_{jv}$\n",
    "- $\\beta_i$ is the node importance score\n",
    "  \n",
    "\n",
    "\n",
    "Then the pagerank can be calculated with power iterations on\n",
    "$$P=\\boldsymbol{\\gamma} \\odot MP + (1-\\boldsymbol{\\gamma}) \\odot \\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$$\n",
    "\n",
    "Where:\n",
    "- $1-\\boldsymbol{\\gamma}$ is a vector of hyperparameters representing the probability of randomly teleporting from a given node\n",
    "- $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$ is the vectorized version of $\\beta_{i}/\\sum_{i\\in V}\\beta_i$\n",
    "\n",
    "---\n",
    "*note the other formulation in the paper results in a dense transition matrix that is nxn.... too big*\n",
    "\n",
    "*note that for $m_{ij}$, $i$ is the target and $j$ is the source*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "157b8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = 1\n",
    "REVERSE = True\n",
    "\n",
    "DATAPATH = Path('../data/processed/pagerank')\n",
    "OUTPATH = DATAPATH.parent / 'nodes_custom_rev_new.parquet'\n",
    "\n",
    "n_df = pd.read_parquet(DATAPATH / 'input_node_scores.parquet')\n",
    "e_df = pd.read_parquet(DATAPATH / 'input_edge_scores.parquet')\n",
    "e_df = e_df[['cust_id_sender', 'cust_id_receiver', 'score']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98042e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reversing edges\n",
    "if REVERSE:\n",
    "    e2_df = pd.DataFrame()\n",
    "    e2_df['cust_id_receiver'] = e_df['cust_id_sender'].copy()\n",
    "    e2_df['cust_id_sender'] = e_df['cust_id_receiver'].copy()\n",
    "    e2_df['score'] = e_df['score']\n",
    "\n",
    "    e_df = pd.concat([e_df, e2_df])\n",
    "    e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344371c",
   "metadata": {},
   "source": [
    "## Constructing $\\boldsymbol{\\beta}/||\\boldsymbol{\\beta}||_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a7702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nodes in the graph\n",
    "node_list = []\n",
    "node_list.extend(e_df.cust_id_sender.tolist() + e_df.cust_id_receiver.tolist() + n_df.cust_id.tolist())\n",
    "node_list = list(set(node_list)) #hack to remove duplicate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b179828a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>b_i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45369</th>\n",
       "      <td>CUST76986222</td>\n",
       "      <td>0.000672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297352</th>\n",
       "      <td>CUST60968343</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78822</th>\n",
       "      <td>CUST73079564</td>\n",
       "      <td>0.000624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cust_id       b_i\n",
       "45369   CUST76986222  0.000672\n",
       "297352  CUST60968343  0.000662\n",
       "78822   CUST73079564  0.000624"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct B\n",
    "b_df = pd.DataFrame(data={'cust_id':node_list})\n",
    "b_df = b_df.merge(n_df, on='cust_id', how='left')\n",
    "b_df = b_df.rename(columns={'score':'b_i'})\n",
    "b_df = b_df.fillna(0)\n",
    "\n",
    "one_norm = abs(b_df['b_i']).sum()\n",
    "\n",
    "b_df['b_i'] = b_df['b_i'] / one_norm\n",
    "\n",
    "b_df.sort_values('b_i', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ab29c6",
   "metadata": {},
   "source": [
    "## Node Encoding\n",
    "This section encodes the cust_ids ordinally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e3db642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358723</th>\n",
       "      <td>198730</td>\n",
       "      <td>129150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448030</th>\n",
       "      <td>3402</td>\n",
       "      <td>60617</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259499</th>\n",
       "      <td>277289</td>\n",
       "      <td>88040</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cust_id_sender  cust_id_receiver  score\n",
       "358723          198730            129150    0.0\n",
       "448030            3402             60617    0.0\n",
       "259499          277289             88040    0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(node_list)\n",
    "\n",
    "e_df['cust_id_sender'] = le.transform(e_df['cust_id_sender'])\n",
    "e_df['cust_id_receiver'] = le.transform(e_df['cust_id_receiver'])\n",
    "\n",
    "b_df['cust_id'] = le.transform(b_df['cust_id'])\n",
    "\n",
    "node_enc = le.transform(node_list)\n",
    "\n",
    "e_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c0b9d0",
   "metadata": {},
   "source": [
    "## Constructing $M$\n",
    "*note that for $m_{ij}$, $i$ is the target node and $j$ is the source node*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08d50828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>569448</th>\n",
       "      <td>140594</td>\n",
       "      <td>183582</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.420</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858449</th>\n",
       "      <td>216270</td>\n",
       "      <td>144765</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103521</th>\n",
       "      <td>287614</td>\n",
       "      <td>49949</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097844</th>\n",
       "      <td>285925</td>\n",
       "      <td>129779</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081536</th>\n",
       "      <td>281039</td>\n",
       "      <td>151106</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31587</th>\n",
       "      <td>7857</td>\n",
       "      <td>215306</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372084</th>\n",
       "      <td>91841</td>\n",
       "      <td>239067</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070585</th>\n",
       "      <td>277865</td>\n",
       "      <td>17866</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353888</th>\n",
       "      <td>87326</td>\n",
       "      <td>35919</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125377</th>\n",
       "      <td>30478</td>\n",
       "      <td>31986</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cust_id_sender  cust_id_receiver  score   w_ji  a_ji    s_j  d_j\n",
       "569448           140594            183582  0.010  0.010     1  0.420   17\n",
       "858449           216270            144765  0.010  0.010     1  0.215    9\n",
       "1103521          287614             49949  0.010  0.010     1  0.355   23\n",
       "1097844          285925            129779  0.010  0.010     1  0.020    2\n",
       "1081536          281039            151106  0.135  0.135     1  0.610   11\n",
       "31587              7857            215306  0.010  0.010     1  0.500   25\n",
       "372084            91841            239067  0.135  0.135     1  0.665    4\n",
       "1070585          277865             17866  0.010  0.010     1  0.010    1\n",
       "353888            87326             35919  0.010  0.010     1  0.030    3\n",
       "125377            30478             31986  0.135  0.135     1  0.145    2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_df['score'] += 0.01 #No edges can have 0 weight, so we add a relatively small value to all edges\n",
    "\n",
    "#Calculate w_ji\n",
    "w_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].sum()\n",
    "w_df = w_df.rename(columns={'score':'w_ji'})\n",
    "e_df = e_df.merge(w_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate a_ji\n",
    "a_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False)['score'].count()\n",
    "# a_df = e_df.groupby \n",
    "a_df = a_df.rename(columns={'score':'a_ji'})\n",
    "e_df = e_df.merge(a_df, on=['cust_id_sender', 'cust_id_receiver'], how='left')\n",
    "\n",
    "#Calculate s_j\n",
    "s_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].sum()\n",
    "s_df = s_df.rename(columns={'score':'s_j'})\n",
    "e_df = e_df.merge(s_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Calculate d_j\n",
    "d_df = e_df.groupby(['cust_id_sender'], as_index=False)['score'].count()\n",
    "d_df = d_df.rename(columns={'score':'d_j'})\n",
    "e_df = e_df.merge(d_df, on='cust_id_sender', how='left')\n",
    "\n",
    "#Remove duplicate edges... taking max is just a hack\n",
    "e_df = e_df.groupby(['cust_id_sender', 'cust_id_receiver'], as_index=False).max()\n",
    "\n",
    "e_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9de0561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(r): \n",
    "    m = THETA*r.w_ji/r.s_j + (1-THETA)*r.a_ji/r.d_j\n",
    "    return m\n",
    "\n",
    "#calculate m_ij for sender j, receiver i\n",
    "e_df['m'] = e_df.apply(lambda r: calc_m(r), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2749087b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id_receiver</th>\n",
       "      <th>score</th>\n",
       "      <th>w_ji</th>\n",
       "      <th>a_ji</th>\n",
       "      <th>s_j</th>\n",
       "      <th>d_j</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cust_id_sender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91885</th>\n",
       "      <td>354058</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288107</th>\n",
       "      <td>237774</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207348</th>\n",
       "      <td>249041</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.155</td>\n",
       "      <td>3</td>\n",
       "      <td>0.465</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id_receiver  score   w_ji  a_ji    s_j  d_j    m\n",
       "cust_id_sender                                                       \n",
       "91885                     354058  0.155  0.155     3  0.465    9  1.0\n",
       "288107                    237774  0.155  0.155     3  0.465    9  1.0\n",
       "207348                    249041  0.155  0.155     3  0.465    9  1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify matrix is column stochastic... m should all be 1.0\n",
    "e_df.groupby('cust_id_sender').sum().sort_values('m', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c91330d",
   "metadata": {},
   "source": [
    "## Calculate $\\boldsymbol{\\gamma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "866c14f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57031674, 0.59101032, 0.56048818, ..., 0.56048818, 0.56048818,\n",
       "       0.56048818])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate gammas\n",
    "gamma_df = e_df.groupby(['cust_id_sender'], as_index=False)['s_j'].max() #trick, all s_j are the same\n",
    "gamma_df['gamma'] = np.exp(gamma_df['s_j'])/(0.8+np.exp(gamma_df['s_j']))\n",
    "gamma_df = gamma_df.rename(columns={'cust_id_sender': 'cust_id'})\n",
    "\n",
    "# Create gamma array\n",
    "gamma_df = gamma_df.merge(b_df, on='cust_id', how='right') #trick to get all node ids\n",
    "gamma_df = gamma_df.fillna(np.exp(0)/(0.8+np.exp(0)))\n",
    "gamma_df = gamma_df.sort_values(['cust_id'])\n",
    "gamma = gamma_df['gamma'].values\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15517c03",
   "metadata": {},
   "source": [
    "## Pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f7300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pagerank(M, B, P, gamma, tol=1e-10, maxit=10000):\n",
    "    \"\"\"Computes the node and edge weighted pagerank using a custom algorithm\n",
    "    \n",
    "    This function takes in a transition matrix, node weights, and an initial pagerank vector\n",
    "    and computes the weighted pagerank, stopping when the difference between iterations is < \n",
    "    tolerence or when the maximum # iterations is reached.\n",
    "    \n",
    "    Args:\n",
    "        M: The transition matrix according to Zhang et al. should be a scipy sparse coordinate matrix (NxN)\n",
    "        B: A numpy array of relative node weights (Nx1)\n",
    "        P: A numpy array vector of initial pageranks, normally just uniform (Nx1) \n",
    "        gamma: An array of probabilities of randomly teleporting from a given node (Nx1)\n",
    "        tol: iteration tolerance - when the maximum RELATIVE change in a node score is below this value, iterations stop\n",
    "        maxit: maximum iterations\n",
    "    \n",
    "    Returns\n",
    "        P: The final pagerank vector, min-max scaled to be in [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    itcount = 0\n",
    "    max_diff = 1000 #placeholder large value\n",
    "    diff_list = []\n",
    "    while (itcount <= maxit) and (max_diff >= tol):\n",
    "           \n",
    "        #Pagerank iter\n",
    "        P_int = np.multiply(gamma,M.dot(P)) + np.multiply((1-gamma),B)\n",
    "                \n",
    "        #Adding leaked pagerank back\n",
    "        #need to do this since we don't preprocess to remove dead ends.\n",
    "        leak = np.sum(P_int)\n",
    "        P_int = P_int + (1-leak)/len(P)\n",
    "        \n",
    "        max_diff = (np.absolute(P-P_int)/P).max()\n",
    "        diff_list.append(max_diff)\n",
    "        itcount += 1\n",
    "        P = P_int\n",
    "        \n",
    "    \n",
    "    print(f'Final max (relative) error: {max_diff:.3}')\n",
    "    print(f'Final iterations: {itcount}')\n",
    "    # Scaling\n",
    "    P = (P - P.min())/(P.max() - P.min())\n",
    "    \n",
    "    return P, diff_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6384a6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final max (relative) error: 9.98e-11\n",
      "Final iterations: 4460\n"
     ]
    }
   ],
   "source": [
    "#Construct necessary matrices\n",
    "i = e_df['cust_id_receiver'].values\n",
    "j = e_df['cust_id_sender'].values\n",
    "m = e_df['m'].values\n",
    "\n",
    "N = b_df.shape[0]\n",
    "B = b_df.sort_values('cust_id')['b_i'].values\n",
    "M = coo_array((m,(i,j)), shape=(N,N))\n",
    "P = np.full(N, 1/N)\n",
    "\n",
    "#Run Pagerank\n",
    "P, dl = custom_pagerank(M, B, P, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf5ff1",
   "metadata": {},
   "source": [
    "## Exporting for Webapp\n",
    "The pagerank data needs to be converted back into KYC-esque data, with customer names, countries, etc. but this needs to include *external customers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3686427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pagerank_results(pagerank_df):\n",
    "    \"\"\"Takes in a [id, score] dataframe and turns it back into KYC-style data\"\"\"\n",
    "    \n",
    "    datapath = Path('../data/processed/')\n",
    "    \n",
    "    kyc_df = pd.read_parquet(datapath / 'kyc.parquet')\n",
    "    wdf = pd.read_parquet(datapath / 'wire.parquet')\n",
    "    edf = pd.read_parquet(datapath / 'emt.parquet')\n",
    "    \n",
    "    cleaned = pagerank_df.copy()\n",
    "    \n",
    "    # Join with kyc data and add country column\n",
    "    kyc_df['country'] = 'CA'\n",
    "    cleaned = pd.merge(cleaned, kyc_df, how='left', on='cust_id')\n",
    "\n",
    "    # Get additional countries from wiretransfer data\n",
    "    s1 = wdf[['cust_id_sender', 'country_sender']].copy().rename(columns={'cust_id_sender':'cust_id', 'country_sender':'country'})\n",
    "    s2 = wdf[['cust_id_receiver', 'country_receiver']].copy().rename(columns={'cust_id_receiver':'cust_id', 'country_receiver':'country'})\n",
    "    countries = pd.concat([s1,s2])\n",
    "    countries = countries.drop_duplicates()\n",
    "\n",
    "    cleaned = pd.merge(cleaned, countries, how='left', on='cust_id')\n",
    "    cleaned['country_x'] = cleaned['country_x'].combine_first(cleaned['country_y'])\n",
    "    cleaned['country'] = cleaned['country_x']\n",
    "    cleaned = cleaned.drop(columns=['country_x', 'country_y'])\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70503f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df = pd.DataFrame(data=P, columns=['score'])\n",
    "P_df['cust_id'] = P_df.index\n",
    "P_df['cust_id'] = le.inverse_transform(P_df['cust_id']) #transform back to actual IDS\n",
    "P_df = P_df[['cust_id','score']]\n",
    "P_df = clean_pagerank_results(P_df)\n",
    "P_df.to_parquet(OUTPATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:imibigdata]",
   "language": "python",
   "name": "conda-env-imibigdata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
